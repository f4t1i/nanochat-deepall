"""
Kaggle Notebook Cells - Kopiere diese Zellen in dein Kaggle Notebook
"""

# ============================================================
# ZELLE 1: Setup & Dependencies
# ============================================================
print("=" * 60)
print("ğŸš€ DeepMaster Fine-Tuning Setup")
print("=" * 60)

# Installiere Dependencies
import subprocess
import sys

print("\nğŸ“¦ Installiere Dependencies...")
subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "tiktoken", "torch"])
print("âœ… Dependencies installiert")

# PrÃ¼fe GPU
import torch
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"\nğŸ–¥ï¸  Device: {device}")
if device == "cuda":
    print(f"   GPU: {torch.cuda.get_device_name(0)}")
    print(f"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

# ============================================================
# ZELLE 2: PrÃ¼fe Dataset
# ============================================================
print("\n" + "=" * 60)
print("ğŸ“‚ PrÃ¼fe Dataset")
print("=" * 60)

from pathlib import Path
import os

input_dir = Path('/kaggle/input/deepmaster')
print(f"\nğŸ“ Input Directory: {input_dir}")
print(f"   Existiert: {input_dir.exists()}")

if input_dir.exists():
    print("\n   Dateien:")
    for f in sorted(input_dir.iterdir()):
        size = f.stat().st_size / (1024**2) if f.is_file() else 0
        if f.is_file():
            print(f"   âœ… {f.name} ({size:.1f} MB)")
        else:
            print(f"   ğŸ“ {f.name}/")
else:
    print("\n   âŒ FEHLER: Dataset nicht gefunden!")
    print("   Stelle sicher, dass du das Dataset als INPUT hinzugefÃ¼gt hast!")

# ============================================================
# ZELLE 3: Lade Modell
# ============================================================
print("\n" + "=" * 60)
print("ğŸ§  Lade Modell")
print("=" * 60)

model_path = input_dir / 'DeepMaster_converted.pt'
print(f"\nğŸ“‚ Modell: {model_path}")
print(f"   Existiert: {model_path.exists()}")

if model_path.exists():
    ckpt = torch.load(model_path, map_location=device, weights_only=False)
    print(f"   âœ… Geladen")
    print(f"   Config: {ckpt['model_args']}")
else:
    print(f"   âŒ FEHLER: Modell nicht gefunden!")

# ============================================================
# ZELLE 4: Lade Trainingsdaten
# ============================================================
print("\n" + "=" * 60)
print("ğŸ“š Lade Trainingsdaten")
print("=" * 60)

data_path = input_dir / 'training_data.txt'
print(f"\nğŸ“„ Daten: {data_path}")
print(f"   Existiert: {data_path.exists()}")

if data_path.exists():
    all_text = data_path.read_text(encoding='utf-8', errors='ignore')
    print(f"   âœ… Geladen")
    print(f"   GrÃ¶ÃŸe: {len(all_text):,} Zeichen")
    
    # Tokenize
    import tiktoken
    enc = tiktoken.get_encoding("gpt2")
    tokens = enc.encode(all_text)
    print(f"   Tokens: {len(tokens):,}")
else:
    print(f"   âŒ FEHLER: Trainingsdaten nicht gefunden!")

# ============================================================
# ZELLE 5: Starte Training
# ============================================================
print("\n" + "=" * 60)
print("ğŸ”¥ Starte Training")
print("=" * 60)

# FÃ¼hre das Training Script aus
exec(open('/kaggle/input/deepmaster/kaggle_train.py').read())

# ============================================================
# ZELLE 6: Verify Output
# ============================================================
print("\n" + "=" * 60)
print("âœ… Verify Output")
print("=" * 60)

output_dir = Path('/kaggle/working')
output_file = output_dir / 'DeepMaster_finetuned.pt'

print(f"\nğŸ“‚ Output: {output_file}")
print(f"   Existiert: {output_file.exists()}")

if output_file.exists():
    size = output_file.stat().st_size / (1024**2)
    print(f"   âœ… GrÃ¶ÃŸe: {size:.1f} MB")
    
    # Lade und prÃ¼fe
    ckpt = torch.load(output_file, map_location=device, weights_only=False)
    print(f"   âœ… Kann geladen werden")
    print(f"   Keys: {list(ckpt.keys())}")
    print(f"\nâœ… Training erfolgreich!")
else:
    print(f"   âŒ FEHLER: Output nicht gefunden!")

