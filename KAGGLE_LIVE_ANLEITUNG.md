# üöÄ Kaggle Live Anleitung - JETZT STARTEN!

## üìç Du bist auf Kaggle - Folge diesen Schritten:

---

## **SCHRITT 1: Dataset hochladen (5 Min)**

### 1.1 Gehe zu Datasets
```
https://www.kaggle.com/settings/datasets
```

### 1.2 Klick "Create new dataset"
- Oben rechts: "+ New Dataset"

### 1.3 Upload 3 Dateien
Lade diese Dateien hoch:
```
‚úÖ DeepMaster_converted.pt    (500 MB)
‚úÖ training_data.txt           (5 MB)
‚úÖ kaggle_train.py             (5 KB)
```

**Wo findest du die Dateien?**
- GitHub: https://github.com/f4t1i/nanochat-deepall
- Oder lokal: `/home/deepall/nanochat/deepall/`

### 1.4 Dataset-Details
- **Name**: `deepmaster`
- **Beschreibung**: "DeepMaster Fine-Tuning Dataset"
- **Lizenz**: Open Data Commons
- Klick "Create"

### 1.5 Warte auf Upload
- Sollte ~5 Minuten dauern
- Status: "Uploaded"

---

## **SCHRITT 2: Notebook erstellen (2 Min)**

### 2.1 Gehe zu Code
```
https://www.kaggle.com/code
```

### 2.2 Klick "+ New Notebook"

### 2.3 W√§hle Einstellungen
- **Language**: Python
- **Notebook Type**: Notebook
- **Accelerator**: GPU (T4 oder P100)
  - T4: Kostenlos, langsamer
  - P100: Schneller, aber begrenzte Stunden

### 2.4 Klick "Create"

---

## **SCHRITT 3: Dataset hinzuf√ºgen (1 Min)**

### 3.1 Rechts im Notebook
- Klick "Input" (rechts oben)
- Klick "+ Add input"
- Suche: "deepmaster"
- W√§hle dein Dataset aus
- Klick "Add"

### 3.2 √úberpr√ºfe
- Rechts sollte jetzt dein Dataset angezeigt werden
- Path: `/kaggle/input/deepmaster/`

---

## **SCHRITT 4: Code eingeben (5 Min)**

### 4.1 Zelle 1: Setup
```python
# Installiere Dependencies
!pip install tiktoken torch -q
print("‚úÖ Dependencies installiert")
```

### 4.2 Zelle 2: Training
```python
# F√ºhre Training Script aus
%run /kaggle/input/deepmaster/kaggle_train.py
```

### 4.3 Zelle 3: Verify
```python
# √úberpr√ºfe ob Training erfolgreich war
import torch
import os

output_path = '/kaggle/working/DeepMaster_finetuned.pt'
if os.path.exists(output_path):
    ckpt = torch.load(output_path, weights_only=False)
    print("‚úÖ Training erfolgreich!")
    print(f"‚úÖ Modell gespeichert: {output_path}")
    print(f"‚úÖ Gr√∂√üe: {os.path.getsize(output_path) / (1024**2):.1f} MB")
else:
    print("‚ùå Modell nicht gefunden")
```

---

## **SCHRITT 5: Ausf√ºhren (30 Min)**

### 5.1 Klick "Run All"
- Oben: "Run All" oder Ctrl+Shift+Enter
- Warte auf Completion

### 5.2 Was passiert?
```
Zelle 1: Dependencies installieren (~2 Min)
Zelle 2: Training l√§uft (~25 Min)
Zelle 3: Verifikation (~1 Min)
```

### 5.3 Fortschritt √ºberwachen
- Logs sollten angezeigt werden
- Loss sollte sinken
- Keine Errors!

---

## **SCHRITT 6: Download (2 Min)**

### 6.1 Nach Training
- Gehe zu "Output" Tab (rechts)
- Sollte `DeepMaster_finetuned.pt` angezeigt werden

### 6.2 Download
- Klick auf die Datei
- Klick "Download"
- Speichere in: `/home/deepall/nanochat/deepall/`

---

## **SCHRITT 7: Lokal testen (1 Min)**

### 7.1 Terminal √∂ffnen
```bash
cd /home/deepall/nanochat
```

### 7.2 Teste das Modell
```bash
python deepall/ask_deepflow.py
```

### 7.3 Gib Prompts ein
```
Prompt: "Was ist DeepFlow?"
Prompt: "Erkl√§re M005"
Prompt: "Ursachen-Wirkungs-Ketten"
```

### 7.4 Vergleiche
- Sollte bessere DeepALL-Antworten geben!
- Vorher: "Why is deep deepflow..."
- Nachher: "DeepFlow ist ein Modul..."

---

## ‚ö†Ô∏è **WICHTIGE TIPPS**

### GPU Speicher
```
Wenn CUDA OOM Error:
  ‚Üí batch_size: 32 ‚Üí 16 in kaggle_train.py
  ‚Üí Oder wechsle zu T4 GPU
```

### Timeout
```
Wenn Notebook timeout:
  ‚Üí max_iters: 1000 ‚Üí 500
  ‚Üí Oder nutze P100 GPU
```

### Fehler
```
Wenn tiktoken error:
  ‚Üí !pip install --upgrade tiktoken

Wenn Dataset nicht gefunden:
  ‚Üí Pr√ºfe ob Dataset als Input hinzugef√ºgt
  ‚Üí Path sollte: /kaggle/input/deepmaster/
```

---

## üìä **Erwartete Ergebnisse**

```
Start Loss:     ~4.3
Final Loss:     ~3.5-4.0
Verbesserung:   ~15-20%
Training Zeit:  ~25-30 Min
```

---

## ‚úÖ **CHECKLISTE**

- [ ] Dataset hochgeladen
- [ ] Notebook erstellt
- [ ] GPU aktiviert
- [ ] Dataset als Input hinzugef√ºgt
- [ ] Code eingegeben
- [ ] "Run All" geklickt
- [ ] Training abgewartet
- [ ] Modell heruntergeladen
- [ ] Lokal getestet
- [ ] Bessere Antworten?

---

## üéØ **ERFOLGS-KRITERIEN**

Training ist erfolgreich wenn:
- ‚úÖ Keine CUDA Errors
- ‚úÖ Loss sinkt kontinuierlich
- ‚úÖ Final Loss < 4.0
- ‚úÖ Modell wird gespeichert
- ‚úÖ Download funktioniert
- ‚úÖ Lokales Testen funktioniert

---

## üÜò **HILFE**

**Problem?**
1. Lese: `deepall/KAGGLE_FINAL_SUMMARY.md` ‚Üí Troubleshooting
2. Pr√ºfe: Kaggle Notebook Logs
3. Versuche: batch_size reduzieren

---

**Status**: üöÄ BEREIT ZUM STARTEN!

**N√§chster Schritt**: Gehe zu https://www.kaggle.com/settings/datasets

